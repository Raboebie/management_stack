# Tabby configuration â€” generated by Ansible
# Routes completions and chat through Ollama

[model.completion.http]
kind = "ollama/completion"
model_name = "{{ tabby_completion_model }}"
api_endpoint = "http://ollama:11434"
prompt_template = "<|fim_prefix|>{prefix}<|fim_suffix|>{suffix}<|fim_middle|>"

[model.chat.http]
kind = "openai/chat"
model_name = "{{ tabby_chat_model }}"
api_endpoint = "http://ollama:11434/v1"

[model.embedding.http]
kind = "ollama/embedding"
model_name = "nomic-embed-text"
api_endpoint = "http://ollama:11434"
