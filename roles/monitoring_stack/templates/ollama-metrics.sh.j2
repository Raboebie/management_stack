#!/bin/sh
# Ollama metrics for Telegraf â€” generated by Ansible
# Polls Ollama API for loaded models and available models, outputs JSON
# Uses nsenter to reach the host network from the Telegraf container
exec nsenter -t 1 -m -- /bin/sh -c '
python3 -c "
import json, sys, urllib.request

def fetch_json(url):
    try:
        req = urllib.request.Request(url)
        with urllib.request.urlopen(req, timeout=5) as resp:
            return json.loads(resp.read())
    except Exception:
        return None

out = {}

# Running models (loaded in VRAM)
ps = fetch_json(\"http://127.0.0.1:{{ ollama_port }}/api/ps\")
if ps and \"models\" in ps:
    models = ps[\"models\"]
    out[\"loaded_models\"] = len(models)
    total_vram = 0
    total_size = 0
    for m in models:
        total_vram += m.get(\"size_vram\", 0)
        total_size += m.get(\"size\", 0)
    out[\"vram_bytes\"] = total_vram
    out[\"total_size_bytes\"] = total_size
    if models:
        out[\"loaded_model_names\"] = \",\".join(m.get(\"name\", \"unknown\") for m in models)
else:
    out[\"loaded_models\"] = 0
    out[\"vram_bytes\"] = 0
    out[\"total_size_bytes\"] = 0

# Available models
tags = fetch_json(\"http://127.0.0.1:{{ ollama_port }}/api/tags\")
if tags and \"models\" in tags:
    out[\"available_models\"] = len(tags[\"models\"])
else:
    out[\"available_models\"] = 0

print(json.dumps(out))
"'
